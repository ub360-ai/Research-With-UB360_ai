"""
Data Cleanup Scheduler for Privacy-First Research Assistant
Automatically deletes documents and chat histories after 48 hours
"""
from apscheduler.schedulers.background import BackgroundScheduler
from datetime import datetime, timedelta
import os
import shutil
from pathlib import Path


class DataCleanupScheduler:
    """Scheduler to automatically cleanup old data for privacy"""
    
    def __init__(self):
        self.scheduler = BackgroundScheduler()
        self.data_retention_hours = 48  # Delete after 48 hours
        
    def start(self):
        """Start the cleanup scheduler"""
        # Run cleanup every 6 hours
        self.scheduler.add_job(
            self.cleanup_old_data,
            'interval',
            hours=6,
            id='data_cleanup',
            replace_existing=True
        )
        self.scheduler.start()
        print(f"âœ… Data cleanup scheduler started (runs every 6 hours)")
        print(f"ðŸ”’ Privacy: Data deleted after {self.data_retention_hours} hours")
    
    def cleanup_old_data(self):
        """Delete documents and data older than retention period"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=self.data_retention_hours)
            deleted_count = 0
            
            # Cleanup uploaded documents
            docs_dir = Path("data/documents")
            if docs_dir.exists():
                for filepath in docs_dir.iterdir():
                    if filepath.is_file():
                        file_mtime = datetime.fromtimestamp(filepath.stat().st_mtime)
                        if file_mtime < cutoff_time:
                            filepath.unlink()
                            deleted_count += 1
                            print(f"ðŸ—‘ï¸  Deleted old document: {filepath.name}")
            
            # Cleanup temporary files
            temp_dir = Path("data/temp")
            if temp_dir.exists():
                for filepath in temp_dir.iterdir():
                    if filepath.is_file():
                        file_mtime = datetime.fromtimestamp(filepath.stat().st_mtime)
                        if file_mtime < cutoff_time:
                            filepath.unlink()
                            deleted_count += 1
            
            # Note: ChromaDB vector store cleanup is handled by the database itself
            # when documents are deleted through the API
            
            print(f"âœ… Cleanup completed at {datetime.now()}")
            print(f"   Deleted {deleted_count} old files")
            
        except Exception as e:
            print(f"âŒ Error during cleanup: {e}")
    
    def stop(self):
        """Stop the cleanup scheduler"""
        self.scheduler.shutdown()
        print("ðŸ›‘ Data cleanup scheduler stopped")
